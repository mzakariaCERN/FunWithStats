{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding error bars to plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a plot connects dots, each derived from averaging, we should expect to see error bars to quantify the certainty in that aggregation. In press, we never see them. Connecting dots alone isn’t enough. Without error bars we can’t have confidence in the pattern of dots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![No Error Bars](Images/2/No_error_bars.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Standard Deviation vs. Standard Error: the eternal confusion. Say we want to estimate the mean (m) of an unknown distribution. We have N independent samples x_i. A simple (though maybe not the best) estimate of m is the average or sample mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{m} = \\frac{1}{N} \\sum_{i=1}^{N} x_{i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " SE tells how good this is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ SE(\\hat{m}) = \\sqrt{var(\\hat{m})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This estimate of m is itself a random quantity. So what we want is to quantify the uncertainty around this estimate (SE). This is not the same as the spread of the samples (SD); but the two are related. The relation is often the source of much confusion. Here’s the SE formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$SE(\\hat{m}) = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} x_{i}}$$  \n",
    "$$ = \\frac{\\sqrt{var(x_{i}}}{\\sqrt{N}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But given only the samples x_i, we don’t know the exact value of the variance var(x_i) of the unknown distribution. So we replace the numerator of the formula for SE with its estimate, the sample standard deviation (SD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$SE \\approx \\frac{SD}{\\sqrt{N}} $$, where  \n",
    "$$SD = \\sqrt{\\frac{1}{N} \\sum_{i = 1}^{N}(x_{i} - \\hat{m})^{2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each point on a curve should be reported with error bars that quantify the possible range of values with some confidence. This is always possible because with large enough N, the estimated mean itself behaves like a Gaussian (b/c central limit theorem). For instance, we can report  \n",
    "Upper 95% limit = $\\bar{x}$ + 1.96 SE  \n",
    "Lower 95% limit = $\\bar{x}$ - 1.96 SE  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://twitter.com/docmilanfar/status/1257121280198729729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('EmailO': conda)",
   "language": "python",
   "name": "python37464bitemailoconda80d5ca88bd394217b6c5518c0874cdd8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
